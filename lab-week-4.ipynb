{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab sheet and all other materials can be found on GitHub here: https://github.com/QMUL-ECS735P/lab-week-4/\n",
    "\n",
    "# Introduction to SPARQL\n",
    "> **Session objectives:**\n",
    ">   - Write and execute SPARQL queries\n",
    ">   - Merge RDF data from multiple sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "As with the last lab, we'll be using Python to create SPARQL database queries and constructing RDF graphs from those queries.\n",
    "\n",
    "If you're new to Python it would be wise to keep the basic tutorial handy for reference: \n",
    "- https://docs.python.org/3.7/tutorial/. \n",
    "\n",
    "Python scripts are run by calling the `python` command, followed by the name of the python script to execute, for example:\n",
    "\n",
    "```bash\n",
    "python3 hello_world.py\n",
    "```\n",
    "\n",
    "It is also possible to run python in an interactive mode known as a REPL, to do this simply call `python` without any arguments:\n",
    "\n",
    "```\n",
    "python3\n",
    "```\n",
    "\n",
    "If you are using one of the machines in the ITL, you will be able to follow along with this lab sheet with minimal fuss. Make sure you boot into **Linux** and not Windows. If you would like to use your own computer, you'll need to make sure you have python installed as well as the following additional libraries:\n",
    "- sparql-wrapper: https://github.com/RDFLib/sparqlwrapper\n",
    "- rdflib: https://github.com/RDFLib/rdflib\n",
    "- pyparsing: http://pyparsing.wikispaces.com/\n",
    "- networkx: http://networkx.lanl.gov/\n",
    "\n",
    "To run the interactive notebooks, you will also need to install Jupyter: https://jupyter.org/\n",
    "\n",
    "Along with this lab sheet you should also find `using-itl.txt` and `using-laptop.txt` which will run through the steps necessary to get things working on either the ITL computers or your own laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing SPARQL Queries\n",
    "In this lab we'll be using an eternal API endpoint hosted by DBpedia. DBpedia is a community-run resource that extracts linked data from Wikipedia.\n",
    "\n",
    "To write SPARQL queries as python strings, we'll be making good use of multi-line strings:\n",
    "\n",
    "```python\n",
    "this is\n",
    "a multiline\n",
    "string\n",
    "```\n",
    "\n",
    "Begin by importing the SPARQLWrapper library, and supressing some warnings to make the output clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBpedia has a SPARQL endpoint located at `http://dbpedia.org/sparql`. We're going to wrap that endpoint using the SPARQLWrapper, which means we can use a lot of handy methods to construct, exectue, and receive queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = SPARQLWrapper('http://dbpedia.org/sparql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to write a simple SPARQL query to get some information from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.setQuery('''\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbpr: <http://dbpedia.org/resource/>\n",
    "SELECT ?label\n",
    "WHERE { dbpr:Asturias rdfs:label ?label }\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we execute the query, look at how the query is constructed. Does it look familiar?\n",
    "\n",
    "The endpoint can respond in a variety of different serialisation formats, for today we'll be using JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.setReturnFormat(JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to execute the query and print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asturias\n",
      "منطقة أستورياس\n",
      "Asturien\n",
      "Asturias\n",
      "Asturies\n",
      "Asturie\n",
      "アストゥリアス州\n",
      "Asturië (regio)\n",
      "Asturia\n",
      "Astúrias\n",
      "Астурия\n",
      "阿斯图里亚斯\n"
     ]
    }
   ],
   "source": [
    "results = endpoint.query().convert()\n",
    "\n",
    "for result in results['results']['bindings']:\n",
    "    print(result['label']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to unpack what's happening here. First we execute the query with `endpoint.query()` and then tell the SPARQLWrapper library to convert the response into Python nested dictionaries with `.convert()`.\n",
    "\n",
    "We then iterate over the array contained in `results['results']['bindings']` and print each value contained in `result['label']['value']`.\n",
    "\n",
    "To get a better idea of how the `results` dictionary is structured we can use the `pprint` library to pretty print the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'head': {'link': [], 'vars': ['label']},\n",
      "  'results': { 'bindings': [ { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturias',\n",
      "                                          'xml:lang': 'en'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'منطقة أستورياس',\n",
      "                                          'xml:lang': 'ar'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturien',\n",
      "                                          'xml:lang': 'de'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturias',\n",
      "                                          'xml:lang': 'es'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturies',\n",
      "                                          'xml:lang': 'fr'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturie',\n",
      "                                          'xml:lang': 'it'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'アストゥリアス州',\n",
      "                                          'xml:lang': 'ja'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturië (regio)',\n",
      "                                          'xml:lang': 'nl'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Asturia',\n",
      "                                          'xml:lang': 'pl'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Astúrias',\n",
      "                                          'xml:lang': 'pt'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': 'Астурия',\n",
      "                                          'xml:lang': 'ru'}},\n",
      "                             { 'label': { 'type': 'literal',\n",
      "                                          'value': '阿斯图里亚斯',\n",
      "                                          'xml:lang': 'zh'}}],\n",
      "               'distinct': False,\n",
      "               'ordered': True}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pretty = PrettyPrinter(indent = 2)\n",
    "\n",
    "pretty.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to familiarse with this data structure, all our responses from DBpedia will be in a similar format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the FILTER constraint to filter out all responses other than those in English and Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.setQuery('''\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbpr: <http://dbpedia.org/resource/>\n",
    "SELECT ?label\n",
    "WHERE { \n",
    "  dbpr:Asturias rdfs:label ?label .\n",
    "  FILTER( LANG(?label)=\"es\" || LANG(?label)=\"en\") . \n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll execute the query and print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asturias\n",
      "Asturias\n"
     ]
    }
   ],
   "source": [
    "results = endpoint.query().convert()\n",
    "\n",
    "for result in results['results']['bindings']:\n",
    "    print(result['label']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't need to specify the endpoint url or return format because we already did that previously. You can read more about the FILTER constraint here: https://jena.apache.org/tutorials/sparql_filters.html.\n",
    "\n",
    "Try changing the query to select responses in some languages that aren't English or Spanish. (Hint, run the query with no FILTER and look at the `xml:lang` predicate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using SPARQLWrapper and rdflib together\n",
    "Now we'll use our knowledge from last week to create an RDF graph and populate it with the result from some SPARQL queries.\n",
    "\n",
    "For clarity, let's import everything we need first (even though some of these things are already imported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import plugin\n",
    "from rdflib.graph import Graph\n",
    "from rdflib.namespace import Namespace\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, XML\n",
    "\n",
    "endpoint = SPARQLWrapper('http://dbpedia.org/sparql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a CONSTRUCT query which tells SPARQL to construct new rdf triples based on the result of the query. For simplicity we'll simply create an exact copy of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "CONSTRUCT {\n",
    "    <%(uri)s> a ?type .\n",
    "    <%(uri)s> ?property ?value .\n",
    "    <%(uri)s> rdfs:label ?label .\n",
    "    ?value rdfs:label ?vlabel .\n",
    "    ?property rdfs:label ?plabel . \n",
    "}\n",
    "WHERE {\n",
    "    <%(uri)s> a ?type.\n",
    "    <%(uri)s> ?property ?value .\n",
    "    <%(uri)s> rdfs:label ?label .\n",
    "    ?value rdfs:label ?vlabel .\n",
    "    ?property rdfs:label ?plabel . \n",
    "    \n",
    "    FILTER( LANG(?label)=\"es\" || LANG(?label)=\"en\" ) . \n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above query string is using a Python feature called _named placeholders_. You can read a bit about them here: https://www.dummies.com/programming/python/use-named-arguments-in-format-strings/\n",
    "\n",
    "We use the `%` operator to replace the named placeholders with another string, it saves us some typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.setQuery(query % { 'uri': 'http://dbpedia.org/resource/Asturias' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll set the return format to XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.setReturnFormat(XML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then execute the query (note: this may take a little time, don't worry!) While this query executes, you might want to take the time to go over the lecture notes if anything was unclear, or look back at last week's lab sheet to refresh your memory of the rdflib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = endpoint.query().convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be a few errors, this is OK we can ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `graph` variable is an rdflib graph like the ones we were creating and manipulating last week. Today we'll use a new method, `graph.query` to write SPARQL queries for our local rdf g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "PREFIX dbpo: <http://dbpedia.org/ontology/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "SELECT DISTINCT ?location ?party ?leader\n",
    "WHERE {\n",
    "    <%(uri)s> rdfs:label ?location .\n",
    "    <%(uri)s> dbpo:leaderName ?leaderResource .\n",
    "    ?leaderResource rdfs:label ?leader .\n",
    "    <%(uri)s> dbpo:leaderParty ?partyResource .\n",
    "    ?partyResource rdfs:label ?party .\n",
    "    FILTER( LANG(?location)=\"%(lang)s\" && LANG(?party)=\"%(lang)s\" && LANG(?leader)=\"%(lang)s\") . \n",
    "}\n",
    "'''\n",
    "\n",
    "replacements = {\n",
    "  'uri': 'http://dbpedia.org/resource/Asturias',\n",
    "  'lang': 'es'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the query just like we did for our SPARQL endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The leading party of Asturias is Partido Socialista Obrero Español. Their leader is Javier Fernández Fernández.\n"
     ]
    }
   ],
   "source": [
    "results = graph.query(query % replacements)\n",
    "\n",
    "for row in results:\n",
    "    print('The leading party of %s is %s. Their leader is %s.' % row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Interactive DBpedia Endpoint\n",
    "DBpedia provides a web-based tool for writing and testing SPARQL queries. You can access it here: http://dbpedia.org/isparql/\n",
    "\n",
    "On the Advanced tab, type or copy the following query into the text area:\n",
    "\n",
    "```\n",
    "PREFIX dbpedia: <http://dbpedia.org/resource/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbpo: <http://dbpedia.org/ontology/>\n",
    "SELECT DISTINCT ?location ?leader ?party\n",
    "FROM <http://dbpedia.org>\n",
    "WHERE {\n",
    "  dbpedia:Asturias rdfs:label ?location ;\n",
    "  dbpo:leaderName ?leaderResource .\n",
    "  ?leaderResource rdfs:label ?leader .\n",
    "  dbpedia:Asturias dbpo:leaderParty ?partyResource .\n",
    "  ?partyResource rdfs:label ?party .\n",
    "}\n",
    "```\n",
    "\n",
    "You can then click the play button to run the query and explore the results.\n",
    "\n",
    "You may also navigate to the QBE tab (query by example) and click the \"Get from Advanced\" icon (it looks like a sheet of paper with a green download arrow). This will generate a visualisation of the query that can be handy to see what it is you're selecting.\n",
    "\n",
    "Some errors may pop up when loading the query from Advanced, we can ignore those."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
